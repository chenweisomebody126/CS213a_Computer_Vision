{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1(a)Prove that parallel lines in the world reference system are still parallel in the camera reference system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $l_1, l_2$ be two parallel lines in the world reference system and $l_1\\times l_2 = 0$. \n",
    "In the camera reference system with matrix $M$, we have projective two lines $Ml_1, Ml_2$. Since the transformation includes rotation and translation, we can rewrite the $Ml_1 = R(l_1+t)$, $Ml_2 = R(l_2+t)$.    \n",
    "For the translation, trivially, the translation direction is parallel to the line, otherwise it should be called roration instead.    \n",
    "We can use $l_1 \\times t = 0$ and $l_2 \\times t = 0$ to simplify $$Ml_1 \\times Ml_2 = R(l_1+t) \\times R(l_2+t) = Rl_1 \\times Rl_2 + R\\times l_1 + R\\times l_2 + l_1 \\times l_2$$,\n",
    "$$= Rl_1 \\times Rl_2 +0 +0 +0 = R(l_1\\times l_2) = 0$$, since R is the rotation matrix with $det(M) =1$.   \n",
    "Two lines are still paralell in the camera reference system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1(b) Consider a unit square pqrs in the world reference system where p, q, r, and s are points. Will the same square in the camera reference system always have unit area? Prove or provide a counterexample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know in the world reference system, squre $pqrs$ has area 1 unit. => $area = ||(q-p)\\times (s-p)||$. In the camera reference system, $area = ||(Mq-Mp)\\times(Ms-Mp)||$, where M is the transformation matrix. Let $Mp= R(p+t)$, where $R$ is the rotations matrix and $t$ is the translation vector. Similarily, we can have the form of $Mq, Ms$.\n",
    "$$area = || R(q+t)-R(p+t)\\times(R(s+t)-R(p+t))|| = ||R(q-p)\\times R(s-p)||$$\n",
    "Since $R$ is the rotation matrix with $det(R) =1$, $$area = ||R((q-p)\\times(s-p))||$$. Because $R$ and $(q-p)\\times(s-p)$ are square matrices of equal size.\n",
    "$$area = ||R|| \\cdot ||(q-p)\\times(s=p)|| = 1 \\cdot 1 = 1$$\n",
    "In the camera reference system, the area is still 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1(c)Now let’s consider affine transformations, which are any transformations that preserve parallelism. Affine transformations include not only rotations and translations, but also scaling and shearing. Given some vector $p$, an affine transformation is defined as\n",
    "$A(p) = Mp + b$\n",
    "where $M$ is an invertible matrix. Prove that under any affine transformation, the ratio of parallel line segments is invariant, but the ratio of non-parallel line segments is not invariant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We discuss two senario. One is line segments are parallel to each other, the other is not. \n",
    "Let say $l_1 //l_2$ and $l_1 = \\alpha l_2$.   \n",
    "$A(l_1) = A(\\alpha l_2)$. Because the transformation is affine, $\\alpha$ can be taken out, so $||A(l_1) || = || A(\\alpha l_2)||= \\alpha ||A(l_2)||$ and the ratio of parallel line segments is invariant i.e., $\\alpha$.     \n",
    "However, when the line segments are non-parallel, the invariant does not hold. For example, let two line be x-axis and y-axis and we take two segments of length 1, $l_1 = \\begin{pmatrix} 0  \\\\ 1\\end{pmatrix}$, $l_2 = \\begin{pmatrix} 1  \\\\0\\end{pmatrix}$, then we use invertible transformation matrix \n",
    "$M=\\begin{pmatrix}\n",
    "  1 & 2 \\\\\n",
    "  0 & 1 \n",
    " \\end{pmatrix}$, $b = 0 $.  \n",
    " In homogedeous coordinates, $$\n",
    " A(l_1) = \\begin{pmatrix}\n",
    "  1 & 2 & 0 \\\\\n",
    "  0 & 1 & 0 \\\\\n",
    "  0 & 0 & 1\n",
    " \\end{pmatrix}\n",
    " \\cdot\n",
    " \\begin{pmatrix} 0  \\\\ 1 \\\\ 1\\end{pmatrix} \n",
    " = \n",
    "  \\begin{pmatrix} 2  \\\\ 1 \\\\ 1\\end{pmatrix}$$\n",
    "  \n",
    "$$A(l_2) = \\begin{pmatrix}\n",
    "  1 & 2 & 0 \\\\\n",
    "  0 & 1 & 0 \\\\\n",
    "  0 & 0 & 1\n",
    " \\end{pmatrix}\n",
    " \\cdot\n",
    " \\begin{pmatrix} 1  \\\\ 0 \\\\ 1\\end{pmatrix} \n",
    " = \n",
    " \\begin{pmatrix} 1  \\\\ 0 \\\\ 1\\end{pmatrix} \n",
    " $$\n",
    " We can get the resulting two line segments $A(l_1) = \\begin{pmatrix} 2  \\\\ 1\\end{pmatrix}$ and $A(l_2) = \\begin{pmatrix} 1  \\\\ 0\\end{pmatrix}$. We can tell their length ratio is not equal to 1 any more. In other words, the ratio of non-parallel line segments is not invariant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1(d)You have explored whether these three properties hold for affine transformations. Do these properties hold under any projective transformation? Justify briefly in one or two sentences (no proof needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " These properties do NOT neccesarily hold under any projective transformation. The reason that the ratio of parallel line segments is invariant is that the transformation is affine, so the ratio can be taken out of norm. Image if the transformation is projective, then the parallelism does not hold, since two parallel lines may vanish to insersect at a vanishing point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "real_XY = np.load('real_XY.npy')\n",
    "front_image = np.load('front_image.npy')\n",
    "back_image = np.load('back_image.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#2(a)\n",
    "'''\n",
    "COMPUTE_CAMERA_MATRIX\n",
    "Arguments:\n",
    "     real_XY - Each row corresponds to an actual point on the 2D plane\n",
    "     front_image - Each row is the pixel location in the front image where Z=0\n",
    "     back_image - Each row is the pixel location in the back image where Z=150\n",
    "Returns:\n",
    "    camera_matrix - The calibrated camera matrix (3x4 matrix)\n",
    "'''\n",
    "def compute_camera_matrix(real_XY, front_image, back_image):\n",
    "    P_front = np.hstack((real_XY, np.full((real_XY.shape[0], 1), 0), \\\n",
    "                         np.ones((real_XY.shape[0], 1))))\n",
    "    P_back = np.hstack((real_XY, np.full((real_XY.shape[0], 1), 150), \\\n",
    "                        np.ones((real_XY.shape[0], 1))))\n",
    "    P = np.vstack((P_front, P_back))\n",
    "    p_prime = np.vstack((front_image, back_image))\n",
    "    p_prime = np.hstack((p_prime, np.ones((p_prime.shape[0], 1))))\n",
    "    #p_prime = P M\n",
    "    M = np.linalg.lstsq(P, p_prime)[0]\n",
    "    return M.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera Matrix:\n",
      " [[  5.31276507e-01  -1.80886074e-02   1.20509667e-01   1.29720641e+02]\n",
      " [  4.84975447e-02   5.36366401e-01  -1.02675222e-01   4.43879607e+01]\n",
      " [ -1.71208112e-18   2.25600086e-18  -8.35267501e-19   1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "camera_matrix = compute_camera_matrix(real_XY, front_image, back_image)\n",
    "print(\"Camera Matrix:\\n\", camera_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#2(b)\n",
    "'''\n",
    "RMS_ERROR\n",
    "Arguments:\n",
    "     camera_matrix - The camera matrix of the calibrated camera\n",
    "     real_XY - Each row corresponds to an actual point on the 2D plane\n",
    "     front_image - Each row is the pixel location in the front image where Z=0\n",
    "     back_image - Each row is the pixel location in the back image where Z=150\n",
    "Returns:\n",
    "    rms_error - The root mean square error of reprojecting the points back\n",
    "                into the images\n",
    "'''\n",
    "def rms_error(camera_matrix, real_XY, front_image, back_image):\n",
    "    P_front = np.hstack((real_XY, np.full((real_XY.shape[0], 1), 0), \\\n",
    "                         np.ones((real_XY.shape[0], 1))))\n",
    "    P_back = np.hstack((real_XY, np.full((real_XY.shape[0], 1), 150), \\\n",
    "                        np.ones((real_XY.shape[0], 1))))\n",
    "    P = np.vstack((P_front, P_back))\n",
    "    p_prime = np.vstack((front_image, back_image))\n",
    "    #p_prime = P M\n",
    "    calculated_p_prime = np.dot(P,camera_matrix.T)\n",
    "    p_prime = np.hstack((p_prime, np.ones((p_prime.shape[0], 1))))\n",
    "    n = calculated_p_prime.shape[0]\n",
    "    rmse = np.linalg.norm(calculated_p_prime - p_prime) / np.sqrt(n)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMS Error:  0.99383048328\n"
     ]
    }
   ],
   "source": [
    "print(\"RMS Error: \", rms_error(camera_matrix, real_XY, front_image, back_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2(c) Could you calibrate the matrix with only one checkerboard image? Explain briefly in one\n",
    "or two sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No, it depends. If we only use the checkerboard image with Z = 0, then we lack the Z information to solve the linear euqation. So we can NOT calibrate the matrix with this one checkerboard image.\n",
    "However, the image with Z = 150 gives us 12 (X,Y,Z) tuples in Scene Coordinate System and each coordinate provides 2 linear equaation. We have more equations than the number of unknown parameters 8. So we can still compute camera parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import mat2euler\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3(a)\n",
    "'''\n",
    "COMPUTE_VANISHING_POINTS\n",
    "Arguments:\n",
    "    points - a list of all the points where each row is (x, y). Generally,\n",
    "            it will contain four points: two for each parallel line.\n",
    "            You can use any convention you'd like, but our solution uses the\n",
    "            first two rows as points on the same line and the last\n",
    "            two rows as points on the same line.\n",
    "Returns:\n",
    "    vanishing_point - the pixel location of the vanishing point\n",
    "'''\n",
    "def compute_vanishing_point(points):\n",
    "    # reference http://homepages.inf.ed.ac.uk/rbf/CVonline/LOCAL_COPIES/BEARDSLEY/node2.html\n",
    "    p1, q1, p2, q2 = points[0][:], points[1][:], points[2][:], points[3][:] \n",
    "    p1_h, q1_h, p2_h, q2_h = np.hstack(\\\n",
    "        (p1, np.ones(1))), np.hstack((q1, np.ones(1))),\\\n",
    "    np.hstack((p2, np.ones(1))), np.hstack((q2, np.ones(1)))\n",
    "    vanishing_point_h = np.cross(\\\n",
    "            np.cross(p1_h, q1_h), np.cross(p2_h, q2_h) )\n",
    "    vanishing_point = np.array(\\\n",
    "            [vanishing_point_h[0]/vanishing_point_h[2],\\\n",
    "            vanishing_point_h[1]/vanishing_point_h[2]])\n",
    "    return vanishing_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Part A: Compute vanishing points\n",
    "v1 = compute_vanishing_point(np.array([[674,1826],[2456,1060],[1094,1340],[1774,1086]]))\n",
    "v2 = compute_vanishing_point(np.array([[674,1826],[126,1056],[2456,1060],[1940,866]]))\n",
    "v3 = compute_vanishing_point(np.array([[1094,1340],[1080,598],[1774,1086],[1840,478]]))\n",
    "\n",
    "v1b = compute_vanishing_point(np.array([[314,1912],[2060,1040],[750,1378],[1438,1094]]))\n",
    "v2b = compute_vanishing_point(np.array([[314,1912],[36,1578],[2060,1040],[1598,882]]))\n",
    "v3b = compute_vanishing_point(np.array([[750,1378],[714,614],[1438,1094],[1474,494]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3(b)\n",
    "'''\n",
    "COMPUTE_K_FROM_VANISHING_POINTS\n",
    "Arguments:\n",
    "    vanishing_points - a list of vanishing points\n",
    "\n",
    "Returns:\n",
    "    K - the intrinsic camera matrix (3x3 matrix)\n",
    "'''\n",
    "def compute_K_from_vanishing_points(vanishing_points):\n",
    "    vanishing_pairs = [[vanishing_points[0], vanishing_points[1]], \\\n",
    "                       [vanishing_points[1], vanishing_points[2]], \\\n",
    "                       [vanishing_points[2], vanishing_points[0]]]\n",
    "    vanishing_constraints = []\n",
    "    for pair in vanishing_pairs:\n",
    "        u, v = pair[0], pair[1]\n",
    "        vanishing_constraints.append(\\\n",
    "                [u[0]*v[0]+u[1]*v[1], u[0]+v[0], u[1]+v[1]])\n",
    "    vanishing_constraints =np.array(vanishing_constraints)\n",
    "    product= np.full((3, 1), -1)\n",
    "    scaled_w = np.linalg.lstsq(vanishing_constraints, product)[0]\n",
    "    matrix_w= np.array(\\\n",
    "            [[np.asscalar(scaled_w[0]), 0, np.asscalar(scaled_w[1])], \\\n",
    "            [0, np.asscalar(scaled_w[0]), np.asscalar(scaled_w[2])], \\\n",
    "            [np.asscalar(scaled_w[1]), np.asscalar(scaled_w[2]), 1]]) \n",
    "    #matrix_w_inversed_transposed = np.linalg.inv(matrix_w).T\n",
    "    #K = np.linalg.cholesky(matrix_w_inversed_transposed)\n",
    "    L = np.linalg.cholesky(matrix_w)\n",
    "    K= np.linalg.inv(L.T)\n",
    "    return K/(K[2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intrinsic Matrix:\n",
      " [[  2.59416985e+03   0.00000000e+00   7.73289548e+02]\n",
      " [  0.00000000e+00   2.59416985e+03   9.79503278e+02]\n",
      " [  0.00000000e+00   0.00000000e+00   1.00000000e+00]]\n",
      "\n",
      "Actual Matrix:\n",
      " [[  2.44800000e+03   0.00000000e+00   1.25300000e+03]\n",
      " [  0.00000000e+00   2.43800000e+03   9.86000000e+02]\n",
      " [  0.00000000e+00   0.00000000e+00   1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Part B: Compute the camera matrix\n",
    "vanishing_points = [v1, v2, v3]\n",
    "print(\"Intrinsic Matrix:\\n\", \\\n",
    "      compute_K_from_vanishing_points(vanishing_points))\n",
    "\n",
    "K_actual = np.array([[2448.0, 0, 1253.0],[0, 2438.0, 986.0],[0,0,1.0]])\n",
    "print()\n",
    "print(\"Actual Matrix:\\n\", K_actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3(c) Is it possible to compute the camera intrinsic matrix for any set of vanishing points? Similarly, is three vanishing points the minimum required to compute the intrinsic camera matrix? Justify your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No, if the two vanishing lines associated with the vanishing points are parallel, then the $cos (\\theta)$ will be 0 and can not be used to calculate the $w$ and $K$.\n",
    "Yes, three vanishing points the minimum required to compute the intrinsic camera matrix, since there are three degree of freedom in terms of $w_1, w_2, w_3$ which needs at least three constraints to solve it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3(d) The method used to obtain vanishing points is approximate and prone to noise. Discuss approaches to refine this process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we only use two points in each of two lines to identify two parallel lines. However, for each line, we should consider using more than two points to help denoise the line representation so that the vanishing points obtained from these two lines can be calculated more accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3(e)\n",
    "'''\n",
    "COMPUTE_ANGLE_BETWEEN_PLANES\n",
    "Arguments:\n",
    "    vanishing_pair1 - a list of a pair of vanishing points computed from lines within the same plane\n",
    "    vanishing_pair2 - a list of another pair of vanishing points from a different plane than vanishing_pair1\n",
    "    K - the camera matrix used to take both images\n",
    "\n",
    "Returns:\n",
    "    angle - the angle in degrees between the planes which the vanishing point pair comes from\n",
    "'''\n",
    "def compute_angle_between_planes(vanishing_pair1, vanishing_pair2, K):\n",
    "    w_star  = np.dot(K, K.T)\n",
    "    p1 = np.hstack((vanishing_pair1[0][:], 1))\n",
    "    p2 = np.hstack((vanishing_pair1[1][:], 1))\n",
    "    l1 = np.cross(p1, p2)\n",
    "    q1 = np.hstack((vanishing_pair2[0], 1))\n",
    "    q2 = np.hstack((vanishing_pair2[1], 1))\n",
    "    l2 = np.cross(q1, q2)\n",
    "    cosine = np.dot(np.dot(l1.T, w_star), l2)\\\n",
    "    / np.sqrt(np.dot(np.dot(l1.T, w_star), l1)) \\\n",
    "    / np.sqrt(np.dot(np.dot(l2.T, w_star), l2))\n",
    "    angle = np.arccos(cosine)\n",
    "    return angle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Angle between floor and box: 1.57127387054\n"
     ]
    }
   ],
   "source": [
    "# Part D: Estimate the angle between the box and floor\n",
    "floor_vanishing1 = v1\n",
    "floor_vanishing2 = v2\n",
    "box_vanishing1 = v3\n",
    "box_vanishing2 = compute_vanishing_point(\\\n",
    "        np.array([[1094,1340],[1774,1086],[1080,598],[1840,478]]))\n",
    "angle = compute_angle_between_planes(\\\n",
    "        [floor_vanishing1, floor_vanishing2], \\\n",
    "        [box_vanishing1, box_vanishing2], K_actual)\n",
    "print()\n",
    "print(\"Angle between floor and box:\", angle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ground plane is orthogonal to the plane-A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3(f)\n",
    "'''\n",
    "COMPUTE_RATATION_MATRIX_BETWEEN_CAMERAS\n",
    "Arguments:\n",
    "    vanishing_points1 - a list of vanishing points in image 1\n",
    "    vanishing_points2 - a list of vanishing points in image 2\n",
    "    K - the camera matrix used to take both images\n",
    "\n",
    "Returns:\n",
    "    R - the rotation matrix between camera 1 and camera 2\n",
    "'''\n",
    "def compute_rotation_matrix_between_cameras(vanishing_points1, vanishing_points2, K):\n",
    "    vp1 = np.hstack((vanishing_points1, np.ones((3, 1)))).T\n",
    "    vp2 = np.hstack((vanishing_points2, np.ones((3, 1)))).T\n",
    "    #d1 is directions of vanishing points in first image\n",
    "    d1 = np.array(np.linalg.lstsq(K, vp1)[0])\n",
    "    d1_norm = np.linalg.norm(d1, axis =0)\n",
    "    d1 = d1/d1_norm\n",
    "    #d2 directions of vanishing points in second image\n",
    "    d2 = np.array(np.linalg.lstsq(K, vp2)[0])\n",
    "    d2_norm = np.linalg.norm(d2, axis =0)\n",
    "    d2 = d2/d2_norm\n",
    "    R = np.dot(d2, np.linalg.inv(d1))\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rotation between two cameras:\n",
      " [[ 0.96154157  0.04924778 -0.15783349]\n",
      " [-0.01044314  1.00703585  0.04571333]\n",
      " [ 0.18940319 -0.06891607  1.00470583]]\n",
      "Angle around z-axis (pointing out of camera): -2.931986 degrees\n",
      "Angle around y-axis (pointing vertically): -8.918793 degrees\n",
      "Angle around x-axis (pointing horizontally): -2.605117 degrees\n"
     ]
    }
   ],
   "source": [
    "# Part E: Compute the rotation matrix between the two cameras\n",
    "rotation_matrix = compute_rotation_matrix_between_cameras(\\\n",
    "    np.array([v1, v2, v3]), \\\n",
    "    np.array([v1b, v2b, v3b]), K_actual)\n",
    "print()\n",
    "print(\"Rotation between two cameras:\\n\", rotation_matrix)\n",
    "z,y,x = mat2euler(rotation_matrix)\n",
    "print\n",
    "print(\"Angle around z-axis (pointing out of camera): %f degrees\" % (z * 180 / math.pi))\n",
    "print(\"Angle around y-axis (pointing vertically): %f degrees\" % (y * 180 / math.pi))\n",
    "print(\"Angle around x-axis (pointing horizontally): %f degrees\" % (x * 180 / math.pi))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4(a)Show that two 3 × 4 camera matrices $M$ and $M′$ can always be reduced to the following canonical forms by an appropriate projective transformation in 3D space, which is repre- sented by a 4 × 4 matrix $H$. Here, we assume $e_3^T (−A′A^−1b+b′) != 0$, where $e_3 = (0, 0, 1)^T$ , $M = [A,b]$ and $M′ = [A′,b′]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since $\\hat{M} =  MH_o$, $\\hat{M}= \\begin{pmatrix}\n",
    "  1 & 0  & 0 & 0 \\\\\n",
    "  0 & 1  & 0 & 0 \\\\\n",
    "  0 & 0  & 1 & 0 \\end{pmatrix}$\n",
    " and $M = [A_{3\\times 3} \\space b_{3\\times 1}]H_0$ and we know $H_0$ is a 4 by 4 matrix.\n",
    "We observe byb eye that one form of $H_0$ is $\\begin{pmatrix}\n",
    "  A^{-1}  & -A^{-1}b \\\\\n",
    "  0 & 1   \\end{pmatrix}$ so that $\\begin{pmatrix}\n",
    "  1 & 0  & 0 & 0 \\\\\n",
    "  0 & 1  & 0 & 0 \\\\\n",
    "  0 & 0  & 1 & 0 \\end{pmatrix} = [A_{3\\times 3} \\space b_{3\\times 1}] \\begin{pmatrix}\n",
    "  A^{-1}  & -A^{-1}b \\\\\n",
    "  0 & 1   \\end{pmatrix} $\n",
    "Besides, we know that $$1) \\space \\hat{M} = MH_0H_1=\\hat{M}H_1$$ $$2) \\space \\hat{M'} = M'H_0H_1$$\n",
    "The first one let us know the first three rows can be $[I \\space 0]$ so that $$ 1)\n",
    "\\begin{pmatrix}\n",
    "  1 & 0  & 0 & 0 \\\\\n",
    "  0 & 1  & 0 & 0 \\\\\n",
    "  0 & 0  & 1 & 0 \n",
    " \\end{pmatrix} \n",
    " =\n",
    "\\begin{pmatrix}\n",
    "  1 & 0  & 0 & 0 \\\\\n",
    "  0 & 1  & 0 & 0 \\\\\n",
    "  0 & 0  & 1 & 0 \n",
    " \\end{pmatrix} \n",
    " \\cdot\n",
    " \\begin{pmatrix}\n",
    "  1 & 0  & 0 & 0 \\\\\n",
    "  0 & 1  & 0 & 0 \\\\\n",
    "  0 & 0  & 1 & 0 \\\\\n",
    "  y_1 & y_2  & y_3 & y_4 \n",
    " \\end{pmatrix}\n",
    "$$\n",
    "From the second equation, and $$M'H_0 = [A'\\space b'] \\begin{pmatrix}\n",
    "  A^{-1}  & -A^{-1}b \\\\\n",
    "  0 & 1   \\end{pmatrix} = [A'A^{-1}, -A'A^{-1}b+b'] = \n",
    "  \\begin{pmatrix}\n",
    "  x_{11} & x_{12}  & x_{13} & x_{14}\\\\\n",
    "  x_{21} & x_{22}  & x_{23} & x_{24}\\\\\n",
    "  x_{31} & x_{32}  & x_{33} & x_{34}\n",
    " \\end{pmatrix} \n",
    "  $$, we get\n",
    "  $-A'A^{-1}b+b' = [x_i4, x_24, x_34].T$, $e_3^T(-A'A^{-1}b+b') != 0$ means $x_34 != 0$.\n",
    "  \n",
    "$$\n",
    " \\begin{pmatrix}\n",
    "  a_{11} & a_{12}  & a_{13} & b_{1}\\\\\n",
    "  a_{21} & a_{22}  & a_{23} & b_{2}\\\\\n",
    "  0 & 0  & 0 & 1\n",
    " \\end{pmatrix}\n",
    " =\n",
    "  \\begin{pmatrix}\n",
    "  x_{11} & x_{12}  & x_{13} & x_{14}\\\\\n",
    "  x_{21} & x_{22}  & x_{23} & x_{24}\\\\\n",
    "  x_{31} & x_{32}  & x_{33} & x_{34}\n",
    " \\end{pmatrix} \n",
    " \\cdot\n",
    "  \\begin{pmatrix}\n",
    "  1 & 0  & 0 & 0 \\\\\n",
    "  0 & 1  & 0 & 0 \\\\\n",
    "  0 & 0  & 1 & 0 \\\\\n",
    "  y_1 & y_2  & y_3 & y_4 \n",
    " \\end{pmatrix}\n",
    "$$\n",
    "Thus, we can represent $H_1$ as \n",
    "$$\n",
    "H_1 =   \\begin{pmatrix}\n",
    "  1 & 0  & 0 & 0 \\\\\n",
    "  0 & 1  & 0 & 0 \\\\\n",
    "  0 & 0  & 1 & 0 \\\\\n",
    "  -x_{31}/x_{34} & -x_{32}/x_{34}  & -x_{33}/x_{34} & 1/x_{34} \n",
    " \\end{pmatrix} $$ \n",
    " , wehre $x_{ij}$ is the element in i-th row and j-th column in $[A'A^{-1}, -A'A^{-1}b+b']$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4(b)Given a 4 × 4 matrix H representing a projective transformation in 3D space, prove that the fundamental matrices corresponding to the two pairs of camera matrices (M,M′) and (MH,M′H) are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $P$ be an arbitrary point in 3D word reference system and the corresponding homogeneous coordinates associated with two camera matrices $(M,M′)$ are $p = MP, p' = M'P$. According to the definition, the fundamental matrices is the matrix $F$ that satisfying the $pFp' =0$. So after we replace $p$ and $p'$, we get $MPFM'P = 0$. \n",
    "Since the $I = HH^{-1}$, we plug in the I between M and P and between M' and P. Then we obtain $MHH^{-1}PFM'HH^{-1}P = 0$. Hence, if we let $Q = H^{-1}P$, we have $MHQFM'HQ = 0$. if we let $q= MHQ$ and $q' = M'HQ$, we get $qFq' = 0$ with camera matrices $(MH,M'H )$ to the same point $Q$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4(c)Using the conclusions from (a) and (b), derive the fundamental matrix $F$ of the camera pair $(M,M′)$ using a11, $a_12$, $a_13$, $a_21$, $a_22$, $a_23$, $b_1$, $b_2$. Then use the fact that $F$ is only defined up to a scale factor to construct a seven-parameter expression for $F$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the conclusions in (b), we know that the fundamental matrices corresponding to the two pairs of camera matrices $(M,M′)$ and $(MH,M′H)$ are the same. Since we have $\\hat{M} = MH$ and $\\hat{M'}= M'H$, the fundamental matrix $F$ of the camera pair $(M,M′)$ is equal to the camera pair $(\\hat{M},\\hat{M′})$.\n",
    "$\\hat{M}PF\\hat{M'}P = 0$, and we know $\\hat{M}= [I | 0]$ and $\\hat{M'} = [A|b]$.\n",
    "Based on the hint, The fundamental matrix corresponding to a pair of camera matrices $M$ and $M′$  is equal to $[b]_{×}A$.   \n",
    "$$F = [b]_{×}A = \n",
    " \\begin{pmatrix}\n",
    "  0 & -1  & b_{2} \\\\\n",
    "  1 & 0  & -b_{1} \\\\\n",
    "  -b_{2} & b_{1}  & 0 \n",
    " \\end{pmatrix} \n",
    " \\cdot\n",
    " \\begin{pmatrix}\n",
    "  a_{11} & a_{12}  & a_{13} \\\\\n",
    "  a_{21} & a_{22}  & a_{23} \\\\\n",
    "  0 & 0  & 0 \n",
    " \\end{pmatrix}\n",
    " $$\n",
    " $$F = \n",
    " \\begin{pmatrix}\n",
    "  -a_{21} & -a_{22}  & -a_{23} \\\\\n",
    "  a_{11} & a_{12}  & a_{13} \\\\\n",
    "  -b_{2}a_{11}+b_{1}a_{21} & -b_{2}a_{12}+b_{1}a_{22}  & -b_{2}a_{13}+b_{1}a_{23} \n",
    " \\end{pmatrix} \n",
    "$$\n",
    "We can use one of elements in $F$ normalize F by dividing up the scale factor since the scale factor will affect the product that is equal to 0. So only seven parameter can construct F. For example, if we divide 8-parameter expression of F by $-a_{21}$ so that the left-top element could be 1.\n",
    "$$\n",
    "F = \n",
    " \\begin{pmatrix}\n",
    "   1 & a_{22}/a_{21}  & a_{23}/a_{21} \\\\\n",
    "  -a_{11}/a_{21} & -a_{12}/a_{21}  & -a_{13}/a_{21} \\\\\n",
    "  (b_{2}a_{11}-b_{1}a_{21})/a_{21} & (b_{2}a_{12}-b_{1}a_{22})/a_{21}  & (b_{2}a_{13}-b_{1}a_{23} )/a_{21}\n",
    " \\end{pmatrix} \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
